"""
æ—¶é—´åºåˆ—æ´å¯ŸåŠ©æ‰‹å‘½ä»¤è¡Œæ¥å£

æä¾›å®Œæ•´çš„å‘½ä»¤è¡Œå·¥å…·åŠŸèƒ½ï¼Œæ”¯æŒæ–‡ä»¶è¾“å…¥å’Œå‚æ•°é…ç½®ã€‚
"""

import typer
import pandas as pd
from pathlib import Path
from typing import Optional, List
from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich.progress import Progress, SpinnerColumn, TextColumn
import json

from ..core.data_processor import TimeSeriesProcessor
from ..analysis.model_identifier import ModelIdentifier
from ..estimation.parameter_estimator import ParameterEstimator
from ..evaluation.model_evaluator import ModelEvaluator
from ..visualization.plotter import TimeSeriesPlotter

app = typer.Typer(
    name="tsia",
    help="æ—¶é—´åºåˆ—æ´å¯ŸåŠ©æ‰‹ - æ™ºèƒ½çš„æ—¶é—´åºåˆ—åˆ†æå·¥å…·",
    add_completion=False
)
console = Console()


@app.command()
def analyze(
    file_path: Path = typer.Argument(..., help="æ—¶é—´åºåˆ—æ•°æ®æ–‡ä»¶è·¯å¾„"),
    date_column: Optional[str] = typer.Option(None, "--date-col", "-d", help="æ—¥æœŸåˆ—å"),
    value_column: Optional[str] = typer.Option(None, "--value-col", "-v", help="æ•°å€¼åˆ—å"),
    output_dir: Optional[Path] = typer.Option(None, "--output", "-o", help="è¾“å‡ºç›®å½•"),
    max_p: int = typer.Option(5, "--max-p", help="æœ€å¤§ARé˜¶æ•°"),
    max_q: int = typer.Option(5, "--max-q", help="æœ€å¤§MAé˜¶æ•°"),
    auto_diff: bool = typer.Option(True, "--auto-diff/--no-auto-diff", help="æ˜¯å¦è‡ªåŠ¨å·®åˆ†"),
    save_plots: bool = typer.Option(True, "--save-plots/--no-save-plots", help="æ˜¯å¦ä¿å­˜å›¾è¡¨"),
    verbose: bool = typer.Option(False, "--verbose", "-v", help="è¯¦ç»†è¾“å‡º"),
):
    """
    åˆ†ææ—¶é—´åºåˆ—æ•°æ®ï¼Œè‡ªåŠ¨è¯†åˆ«æ¨¡å‹å¹¶ä¼°è®¡å‚æ•°
    """
    console.print(Panel.fit("ğŸ” æ—¶é—´åºåˆ—æ´å¯ŸåŠ©æ‰‹", style="bold blue"))
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not file_path.exists():
        console.print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}", style="bold red")
        raise typer.Exit(1)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    if output_dir is None:
        output_dir = Path("tsia_output")
    output_dir.mkdir(exist_ok=True)
    
    try:
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            console=console,
        ) as progress:
            
            # 1. åŠ è½½æ•°æ®
            task1 = progress.add_task("ğŸ“Š åŠ è½½æ•°æ®...", total=None)
            processor = TimeSeriesProcessor()
            data = processor.load_data(
                file_path, 
                date_column=date_column, 
                value_column=value_column
            )
            progress.update(task1, description="âœ… æ•°æ®åŠ è½½å®Œæˆ")
            
            console.print(f"ğŸ“ˆ æ•°æ®æ¦‚è§ˆ: {len(data)} ä¸ªè§‚æµ‹å€¼")
            if verbose:
                console.print(f"   æ•°æ®èŒƒå›´: {data.index[0]} åˆ° {data.index[-1]}")
                console.print(f"   æ•°å€¼èŒƒå›´: {data.min():.4f} åˆ° {data.max():.4f}")
            
            # 2. å¹³ç¨³æ€§æ£€éªŒ
            task2 = progress.add_task("ğŸ”¬ å¹³ç¨³æ€§æ£€éªŒ...", total=None)
            stationarity_result = processor.check_stationarity()
            progress.update(task2, description="âœ… å¹³ç¨³æ€§æ£€éªŒå®Œæˆ")
            
            # æ˜¾ç¤ºå¹³ç¨³æ€§æ£€éªŒç»“æœ
            _display_stationarity_results(stationarity_result)
            
            # 3. å·®åˆ†å¤„ç†
            if auto_diff and not processor.is_stationary:
                task3 = progress.add_task("ğŸ“‰ è‡ªåŠ¨å·®åˆ†å¤„ç†...", total=None)
                diff_data, diff_order = processor.auto_difference()
                progress.update(task3, description=f"âœ… å·®åˆ†å®Œæˆ (é˜¶æ•°: {diff_order})")
                console.print(f"ğŸ”„ å·®åˆ†é˜¶æ•°: {diff_order}")
            else:
                diff_data = data
                diff_order = 0
            
            # 4. æ¨¡å‹è¯†åˆ«
            task4 = progress.add_task("ğŸ¯ æ¨¡å‹è¯†åˆ«...", total=None)
            identifier = ModelIdentifier()
            recommended_models = identifier.identify_arima_order(
                diff_data, max_p=max_p, max_q=max_q, d=diff_order
            )
            progress.update(task4, description="âœ… æ¨¡å‹è¯†åˆ«å®Œæˆ")
            
            # æ˜¾ç¤ºæ¨èæ¨¡å‹
            _display_recommended_models(recommended_models[:5])  # æ˜¾ç¤ºå‰5ä¸ª
            
            # 5. å‚æ•°ä¼°è®¡å’Œæ¨¡å‹è¯„ä¼°
            task5 = progress.add_task("âš™ï¸ å‚æ•°ä¼°è®¡å’Œæ¨¡å‹è¯„ä¼°...", total=None)
            
            best_models = []
            estimator = ParameterEstimator()
            evaluator = ModelEvaluator()
            
            for i, model_info in enumerate(recommended_models[:3]):  # è¯„ä¼°å‰3ä¸ªæ¨¡å‹
                order = model_info['order']
                
                # å‚æ•°ä¼°è®¡
                estimation_results = estimator.estimate_parameters(data, order)
                
                # æ¨¡å‹è¯„ä¼°
                evaluation_result = evaluator.generate_evaluation_report(data, order)
                
                if evaluation_result.get('success', False):
                    model_result = {
                        'order': order,
                        'estimation': estimation_results,
                        'evaluation': evaluation_result,
                        'model_info': model_info
                    }
                    best_models.append(model_result)
            
            progress.update(task5, description="âœ… å‚æ•°ä¼°è®¡å’Œè¯„ä¼°å®Œæˆ")
            
            # 6. ç”Ÿæˆå¯è§†åŒ–
            if save_plots:
                task6 = progress.add_task("ğŸ“Š ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...", total=None)
                plotter = TimeSeriesPlotter()
                
                # åŸå§‹æ•°æ®å›¾
                fig1 = plotter.plot_time_series(data, title="åŸå§‹æ—¶é—´åºåˆ—")
                fig1.savefig(output_dir / "01_original_series.png", dpi=300, bbox_inches='tight')
                
                # ACF/PACFå›¾
                analysis_data = diff_data if diff_order > 0 else data
                fig2 = plotter.plot_acf_pacf(analysis_data, title="ACFå’ŒPACFåˆ†æ")
                fig2.savefig(output_dir / "02_acf_pacf.png", dpi=300, bbox_inches='tight')
                
                # å¦‚æœæœ‰æœ€ä½³æ¨¡å‹ï¼Œç»˜åˆ¶æ®‹å·®è¯Šæ–­
                if best_models:
                    best_model = best_models[0]
                    if 'fitted_model' in best_model['estimation'].get('mle', {}):
                        fitted_model = best_model['estimation']['mle']['fitted_model']
                        residuals = fitted_model.resid
                        fitted_values = fitted_model.fittedvalues
                        
                        fig3 = plotter.plot_residual_diagnostics(
                            residuals, fitted_values, 
                            title=f"æ®‹å·®è¯Šæ–­ - ARIMA{best_model['order']}"
                        )
                        fig3.savefig(output_dir / "03_residual_diagnostics.png", dpi=300, bbox_inches='tight')
                
                progress.update(task6, description="âœ… å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜")
                console.print(f"ğŸ“Š å›¾è¡¨å·²ä¿å­˜åˆ°: {output_dir}")
        
        # 7. æ˜¾ç¤ºæœ€ç»ˆç»“æœ
        _display_final_results(best_models)
        
        # 8. ä¿å­˜ç»“æœåˆ°JSON
        _save_results_to_json(
            output_dir / "analysis_results.json",
            {
                'data_summary': processor.get_summary(),
                'stationarity_test': stationarity_result,
                'recommended_models': recommended_models,
                'best_models': [
                    {
                        'order': m['order'],
                        'model_info': m['model_info'],
                        'evaluation_summary': {
                            'aic': m['evaluation']['fit_statistics']['aic'],
                            'bic': m['evaluation']['fit_statistics']['bic'],
                            'r_squared': m['evaluation']['fit_statistics']['r_squared'],
                            'adequacy_score': m['evaluation']['model_adequacy']['score']
                        }
                    } for m in best_models
                ]
            }
        )
        
        console.print(f"ğŸ’¾ åˆ†æç»“æœå·²ä¿å­˜åˆ°: {output_dir / 'analysis_results.json'}")
        console.print("ğŸ‰ åˆ†æå®Œæˆï¼", style="bold green")
        
    except Exception as e:
        console.print(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}", style="bold red")
        if verbose:
            import traceback
            console.print(traceback.format_exc())
        raise typer.Exit(1)


@app.command()
def quick_check(
    file_path: Path = typer.Argument(..., help="æ—¶é—´åºåˆ—æ•°æ®æ–‡ä»¶è·¯å¾„"),
    date_column: Optional[str] = typer.Option(None, "--date-col", "-d", help="æ—¥æœŸåˆ—å"),
    value_column: Optional[str] = typer.Option(None, "--value-col", "-v", help="æ•°å€¼åˆ—å"),
):
    """
    å¿«é€Ÿæ£€æŸ¥æ—¶é—´åºåˆ—æ•°æ®çš„åŸºæœ¬ä¿¡æ¯
    """
    console.print(Panel.fit("âš¡ å¿«é€Ÿæ•°æ®æ£€æŸ¥", style="bold cyan"))
    
    try:
        # åŠ è½½æ•°æ®
        processor = TimeSeriesProcessor()
        data = processor.load_data(file_path, date_column=date_column, value_column=value_column)
        
        # åŸºæœ¬ä¿¡æ¯
        table = Table(title="æ•°æ®åŸºæœ¬ä¿¡æ¯")
        table.add_column("é¡¹ç›®", style="cyan")
        table.add_column("å€¼", style="magenta")
        
        table.add_row("è§‚æµ‹æ•°é‡", str(len(data)))
        table.add_row("æ•°æ®ç±»å‹", str(data.dtype))
        table.add_row("ç¼ºå¤±å€¼", str(data.isnull().sum()))
        table.add_row("æœ€å°å€¼", f"{data.min():.4f}")
        table.add_row("æœ€å¤§å€¼", f"{data.max():.4f}")
        table.add_row("å‡å€¼", f"{data.mean():.4f}")
        table.add_row("æ ‡å‡†å·®", f"{data.std():.4f}")
        
        if isinstance(data.index, pd.DatetimeIndex):
            table.add_row("å¼€å§‹æ—¶é—´", str(data.index[0]))
            table.add_row("ç»“æŸæ—¶é—´", str(data.index[-1]))
            table.add_row("é¢‘ç‡", str(data.index.freq) if data.index.freq else "ä¸è§„åˆ™")
        
        console.print(table)
        
        # å¹³ç¨³æ€§å¿«é€Ÿæ£€æŸ¥
        stationarity_result = processor.check_stationarity()
        
        status = "âœ… å¹³ç¨³" if stationarity_result['overall']['is_stationary'] else "âŒ éå¹³ç¨³"
        console.print(f"\nğŸ“Š å¹³ç¨³æ€§: {status}")
        
    except Exception as e:
        console.print(f"âŒ æ£€æŸ¥å¤±è´¥: {str(e)}", style="bold red")
        raise typer.Exit(1)


def _display_stationarity_results(results: dict):
    """æ˜¾ç¤ºå¹³ç¨³æ€§æ£€éªŒç»“æœ"""
    table = Table(title="å¹³ç¨³æ€§æ£€éªŒç»“æœ")
    table.add_column("æ£€éªŒæ–¹æ³•", style="cyan")
    table.add_column("ç»Ÿè®¡é‡", style="magenta")
    table.add_column("på€¼", style="yellow")
    table.add_column("ç»“æœ", style="green")
    
    if 'adf' in results:
        adf = results['adf']
        result_text = "âœ… å¹³ç¨³" if adf['is_stationary'] else "âŒ éå¹³ç¨³"
        table.add_row("ADFæ£€éªŒ", f"{adf['statistic']:.4f}", f"{adf['p_value']:.4f}", result_text)
    
    if 'kpss' in results:
        kpss = results['kpss']
        result_text = "âœ… å¹³ç¨³" if kpss['is_stationary'] else "âŒ éå¹³ç¨³"
        table.add_row("KPSSæ£€éªŒ", f"{kpss['statistic']:.4f}", f"{kpss['p_value']:.4f}", result_text)
    
    console.print(table)
    
    if 'overall' in results:
        overall_status = "âœ… å¹³ç¨³" if results['overall']['is_stationary'] else "âŒ éå¹³ç¨³"
        console.print(f"\nğŸ“Š ç»¼åˆåˆ¤æ–­: {overall_status}")


def _display_recommended_models(models: List[dict]):
    """æ˜¾ç¤ºæ¨èæ¨¡å‹"""
    table = Table(title="æ¨èçš„ARIMAæ¨¡å‹")
    table.add_column("æ’å", style="cyan")
    table.add_column("æ¨¡å‹", style="magenta")
    table.add_column("ç½®ä¿¡åº¦", style="yellow")
    table.add_column("æ¨èç†ç”±", style="green")
    
    for i, model in enumerate(models, 1):
        confidence = f"{model['confidence']:.1%}"
        table.add_row(str(i), model['type'], confidence, model['reasoning'])
    
    console.print(table)


def _display_final_results(best_models: List[dict]):
    """æ˜¾ç¤ºæœ€ç»ˆç»“æœ"""
    if not best_models:
        console.print("âŒ æ²¡æœ‰æˆåŠŸæ‹Ÿåˆçš„æ¨¡å‹", style="bold red")
        return
    
    table = Table(title="æ¨¡å‹è¯„ä¼°ç»“æœ")
    table.add_column("æ¨¡å‹", style="cyan")
    table.add_column("AIC", style="magenta")
    table.add_column("BIC", style="yellow")
    table.add_column("RÂ²", style="green")
    table.add_column("é€‚åˆåº¦", style="blue")
    
    for model in best_models:
        eval_result = model['evaluation']
        fit_stats = eval_result['fit_statistics']
        adequacy = eval_result['model_adequacy']
        
        table.add_row(
            f"ARIMA{model['order']}",
            f"{fit_stats['aic']:.2f}",
            f"{fit_stats['bic']:.2f}",
            f"{fit_stats['r_squared']:.3f}",
            f"{adequacy['score']:.0f}% ({adequacy['level']})"
        )
    
    console.print(table)
    
    # æ˜¾ç¤ºæœ€ä½³æ¨¡å‹çš„è¯¦ç»†ä¿¡æ¯
    best_model = best_models[0]
    console.print(f"\nğŸ† æ¨èæ¨¡å‹: ARIMA{best_model['order']}")
    console.print(f"ğŸ“Š æ¨¡å‹é€‚åˆåº¦: {best_model['evaluation']['model_adequacy']['interpretation']}")


def _save_results_to_json(file_path: Path, results: dict):
    """ä¿å­˜ç»“æœåˆ°JSONæ–‡ä»¶"""
    # è½¬æ¢ä¸å¯åºåˆ—åŒ–çš„å¯¹è±¡
    def convert_for_json(obj):
        if hasattr(obj, 'tolist'):
            return obj.tolist()
        elif hasattr(obj, 'to_dict'):
            return obj.to_dict()
        elif isinstance(obj, pd.Timestamp):
            return str(obj)
        elif isinstance(obj, (pd.Series, pd.DataFrame)):
            return obj.to_dict()
        return obj
    
    # é€’å½’è½¬æ¢
    def clean_dict(d):
        if isinstance(d, dict):
            return {k: clean_dict(v) for k, v in d.items()}
        elif isinstance(d, list):
            return [clean_dict(item) for item in d]
        else:
            return convert_for_json(d)
    
    cleaned_results = clean_dict(results)
    
    with open(file_path, 'w', encoding='utf-8') as f:
        json.dump(cleaned_results, f, ensure_ascii=False, indent=2)


@app.command()
def version():
    """æ˜¾ç¤ºç‰ˆæœ¬ä¿¡æ¯"""
    from .. import __version__
    console.print(f"æ—¶é—´åºåˆ—æ´å¯ŸåŠ©æ‰‹ v{__version__}")


if __name__ == "__main__":
    app()
