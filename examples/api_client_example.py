"""
æ—¶é—´åºåˆ—æ´å¯ŸåŠ©æ‰‹ API å®¢æˆ·ç«¯ç¤ºä¾‹

æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨Pythonå®¢æˆ·ç«¯è°ƒç”¨APIæœåŠ¡
"""

import requests
import pandas as pd
import numpy as np
import json
import time
from pathlib import Path
from typing import Dict, Any, Optional

class TSIAClient:
    """æ—¶é—´åºåˆ—æ´å¯ŸåŠ©æ‰‹APIå®¢æˆ·ç«¯"""
    
    def __init__(self, base_url: str = "http://localhost:8000/api/v1"):
        """
        åˆå§‹åŒ–å®¢æˆ·ç«¯
        
        Args:
            base_url: APIåŸºç¡€URL
        """
        self.base_url = base_url
        self.session = requests.Session()
        
    def upload_file(self, 
                   file_path: str,
                   date_column: Optional[str] = None,
                   value_column: Optional[str] = None,
                   date_format: Optional[str] = None) -> Dict[str, Any]:
        """
        ä¸Šä¼ æ–‡ä»¶
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            date_column: æ—¥æœŸåˆ—å
            value_column: æ•°å€¼åˆ—å
            date_format: æ—¥æœŸæ ¼å¼
            
        Returns:
            ä¸Šä¼ ç»“æœ
        """
        with open(file_path, 'rb') as f:
            files = {'file': f}
            data = {}
            if date_column:
                data['date_column'] = date_column
            if value_column:
                data['value_column'] = value_column
            if date_format:
                data['date_format'] = date_format
                
            response = self.session.post(f"{self.base_url}/upload/file", files=files, data=data)
            response.raise_for_status()
            return response.json()
    
    def upload_json_data(self, 
                        data: Dict[str, Any],
                        date_column: Optional[str] = None,
                        value_column: Optional[str] = None) -> Dict[str, Any]:
        """
        ä¸Šä¼ JSONæ•°æ®
        
        Args:
            data: JSONæ•°æ®
            date_column: æ—¥æœŸåˆ—å
            value_column: æ•°å€¼åˆ—å
            
        Returns:
            ä¸Šä¼ ç»“æœ
        """
        payload = {"data": data}
        if date_column:
            payload["date_column"] = date_column
        if value_column:
            payload["value_column"] = value_column
            
        response = self.session.post(f"{self.base_url}/upload/json", json=payload)
        response.raise_for_status()
        return response.json()
    
    def analyze_data(self, 
                    file_id: str,
                    auto_diff: bool = True,
                    max_p: int = 5,
                    max_q: int = 5,
                    n_models: int = 3) -> Dict[str, Any]:
        """
        æ‰§è¡Œæ—¶é—´åºåˆ—åˆ†æ
        
        Args:
            file_id: æ–‡ä»¶ID
            auto_diff: æ˜¯å¦è‡ªåŠ¨å·®åˆ†
            max_p: æœ€å¤§ARé˜¶æ•°
            max_q: æœ€å¤§MAé˜¶æ•°
            n_models: è¯„ä¼°çš„æ¨¡å‹æ•°é‡
            
        Returns:
            åˆ†æç»“æœ
        """
        analysis_request = {
            "auto_diff": auto_diff,
            "max_p": max_p,
            "max_q": max_q,
            "n_models": n_models
        }
        
        response = self.session.post(f"{self.base_url}/analysis/{file_id}", json=analysis_request)
        response.raise_for_status()
        return response.json()
    
    def get_analysis_summary(self, analysis_id: str) -> Dict[str, Any]:
        """è·å–åˆ†ææ‘˜è¦"""
        response = self.session.get(f"{self.base_url}/analysis/{analysis_id}/summary")
        response.raise_for_status()
        return response.json()
    
    def predict(self, 
               analysis_id: str,
               steps: int = 10,
               alpha: float = 0.05) -> Dict[str, Any]:
        """
        è¿›è¡Œé¢„æµ‹
        
        Args:
            analysis_id: åˆ†æID
            steps: é¢„æµ‹æ­¥æ•°
            alpha: ç½®ä¿¡æ°´å¹³
            
        Returns:
            é¢„æµ‹ç»“æœ
        """
        prediction_request = {
            "steps": steps,
            "alpha": alpha
        }
        
        response = self.session.post(f"{self.base_url}/analysis/{analysis_id}/predict", json=prediction_request)
        response.raise_for_status()
        return response.json()
    
    def generate_plots(self, 
                      file_id: str,
                      plot_types: list = None,
                      save_format: str = "png") -> Dict[str, Any]:
        """
        ç”Ÿæˆå›¾è¡¨
        
        Args:
            file_id: æ–‡ä»¶ID
            plot_types: å›¾è¡¨ç±»å‹åˆ—è¡¨
            save_format: ä¿å­˜æ ¼å¼
            
        Returns:
            å›¾è¡¨ç”Ÿæˆç»“æœ
        """
        if plot_types is None:
            plot_types = ["original", "acf_pacf"]
            
        plot_request = {
            "plot_types": plot_types,
            "save_format": save_format
        }
        
        response = self.session.post(f"{self.base_url}/visualization/{file_id}/plots", json=plot_request)
        response.raise_for_status()
        return response.json()
    
    def identify_models(self, 
                       file_id: str,
                       max_p: int = 5,
                       max_q: int = 5,
                       max_d: int = 2) -> Dict[str, Any]:
        """è¯†åˆ«æ¨èæ¨¡å‹"""
        params = {
            "max_p": max_p,
            "max_q": max_q,
            "max_d": max_d
        }
        
        response = self.session.post(f"{self.base_url}/models/{file_id}/identify", params=params)
        response.raise_for_status()
        return response.json()
    
    def evaluate_model(self, 
                      file_id: str,
                      p: int,
                      d: int,
                      q: int) -> Dict[str, Any]:
        """è¯„ä¼°æ¨¡å‹"""
        params = {"p": p, "d": d, "q": q}
        
        response = self.session.post(f"{self.base_url}/models/{file_id}/evaluate", params=params)
        response.raise_for_status()
        return response.json()


def create_sample_data():
    """åˆ›å»ºç¤ºä¾‹æ•°æ®"""
    np.random.seed(42)
    dates = pd.date_range('2020-01-01', periods=200, freq='D')
    
    # ç”ŸæˆARIMA(1,1,1)è¿‡ç¨‹
    noise = np.random.randn(200)
    y = np.zeros(200)
    errors = np.zeros(200)
    
    for t in range(1, 200):
        errors[t] = noise[t] + 0.3 * noise[t-1]  # MA(1)
        y[t] = 0.7 * y[t-1] + errors[t]  # AR(1)
    
    # æ·»åŠ è¶‹åŠ¿
    trend = np.linspace(0, 50, 200)
    y = y + trend
    
    df = pd.DataFrame({
        'date': dates,
        'value': y
    })
    
    return df


def main():
    """ä¸»å‡½æ•° - å®Œæ•´çš„APIä½¿ç”¨ç¤ºä¾‹"""
    
    print("ğŸš€ æ—¶é—´åºåˆ—æ´å¯ŸåŠ©æ‰‹ API å®¢æˆ·ç«¯ç¤ºä¾‹")
    print("=" * 50)
    
    # åˆ›å»ºå®¢æˆ·ç«¯
    client = TSIAClient()
    
    try:
        # 1. åˆ›å»ºç¤ºä¾‹æ•°æ®
        print("ğŸ“Š åˆ›å»ºç¤ºä¾‹æ•°æ®...")
        sample_data = create_sample_data()
        sample_file = "sample_data.csv"
        sample_data.to_csv(sample_file, index=False)
        print(f"âœ… ç¤ºä¾‹æ•°æ®å·²ä¿å­˜åˆ° {sample_file}")
        
        # 2. ä¸Šä¼ æ•°æ®
        print("\nğŸ“¤ ä¸Šä¼ æ•°æ®...")
        upload_result = client.upload_file(
            sample_file,
            date_column="date",
            value_column="value"
        )
        file_id = upload_result["file_id"]
        print(f"âœ… æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼ŒID: {file_id}")
        print(f"   æ•°æ®é•¿åº¦: {upload_result['data_preview']['series_info']['length']}")
        
        # 3. è¯†åˆ«æ¨èæ¨¡å‹
        print("\nğŸ” è¯†åˆ«æ¨èæ¨¡å‹...")
        model_identification = client.identify_models(file_id)
        print(f"âœ… æ¨¡å‹è¯†åˆ«å®Œæˆ")
        print(f"   å¹³ç¨³æ€§: {model_identification['stationarity']['interpretation']}")
        print(f"   æ¨èæ¨¡å‹æ•°é‡: {len(model_identification['recommended_models'])}")
        
        # 4. æ‰§è¡Œå®Œæ•´åˆ†æ
        print("\nğŸ”¬ æ‰§è¡Œå®Œæ•´åˆ†æ...")
        analysis_result = client.analyze_data(file_id)
        analysis_id = analysis_result["analysis_id"]
        print(f"âœ… åˆ†æå®Œæˆï¼ŒID: {analysis_id}")
        
        if analysis_result.get("best_model"):
            best_model = analysis_result["best_model"]
            print(f"   æœ€ä½³æ¨¡å‹: ARIMA{best_model['order']}")
            print(f"   AIC: {best_model['statistics']['aic']:.2f}")
        
        # 5. è·å–åˆ†ææ‘˜è¦
        print("\nğŸ“‹ è·å–åˆ†ææ‘˜è¦...")
        summary = client.get_analysis_summary(analysis_id)
        print("âœ… æ‘˜è¦è·å–æˆåŠŸ")
        
        # 6. è¿›è¡Œé¢„æµ‹
        print("\nğŸ”® è¿›è¡Œé¢„æµ‹...")
        prediction_result = client.predict(analysis_id, steps=10)
        forecast_values = prediction_result["forecast_values"]
        print(f"âœ… é¢„æµ‹å®Œæˆ")
        print(f"   é¢„æµ‹æ­¥æ•°: {len(forecast_values)}")
        print(f"   å‰5ä¸ªé¢„æµ‹å€¼: {[f'{v:.2f}' for v in forecast_values[:5]]}")
        
        # 7. ç”Ÿæˆå›¾è¡¨
        print("\nğŸ“ˆ ç”Ÿæˆå›¾è¡¨...")
        plot_result = client.generate_plots(file_id)
        print(f"âœ… å›¾è¡¨ç”Ÿæˆå®Œæˆ")
        print(f"   ç”Ÿæˆçš„å›¾è¡¨: {len(plot_result['data']['plots'])}")
        
        # 8. è¯„ä¼°ç‰¹å®šæ¨¡å‹
        print("\nâš–ï¸ è¯„ä¼°ç‰¹å®šæ¨¡å‹...")
        evaluation_result = client.evaluate_model(file_id, p=1, d=1, q=1)
        print(f"âœ… æ¨¡å‹è¯„ä¼°å®Œæˆ")
        eval_stats = evaluation_result["evaluation"]["fit_statistics"]
        print(f"   ARIMA(1,1,1) - AIC: {eval_stats['aic']:.2f}, RÂ²: {eval_stats.get('r_squared', 'N/A')}")
        
        print("\nğŸ‰ æ‰€æœ‰APIåŠŸèƒ½æµ‹è¯•å®Œæˆï¼")
        
        # æ¸…ç†ç¤ºä¾‹æ–‡ä»¶
        Path(sample_file).unlink(missing_ok=True)
        
    except requests.exceptions.ConnectionError:
        print("âŒ æ— æ³•è¿æ¥åˆ°APIæœåŠ¡ï¼Œè¯·ç¡®ä¿æœåŠ¡å·²å¯åŠ¨")
        print("   å¯åŠ¨å‘½ä»¤: python scripts/start_dev.py")
    except requests.exceptions.HTTPError as e:
        print(f"âŒ APIè¯·æ±‚å¤±è´¥: {e}")
        if hasattr(e.response, 'text'):
            print(f"   é”™è¯¯è¯¦æƒ…: {e.response.text}")
    except Exception as e:
        print(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")


if __name__ == "__main__":
    main()
